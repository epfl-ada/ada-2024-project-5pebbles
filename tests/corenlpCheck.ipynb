{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9362fb82-1bb6-4755-bde4-92f51c8ad737",
   "metadata": {},
   "source": [
    "# Part 1 : Show the content of a XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57954301-70bd-4c00-ba24-63635b994a8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T09:45:57.460338Z",
     "iopub.status.busy": "2024-11-08T09:45:57.459988Z",
     "iopub.status.idle": "2024-11-08T09:45:58.264763Z",
     "shell.execute_reply": "2024-11-08T09:45:58.263021Z",
     "shell.execute_reply.started": "2024-11-08T09:45:57.460302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<?xml-stylesheet href=\"CoreNLP-to-HTML.xsl\" type=\"text/xsl\"?>\n",
      "<root>\n",
      "<document>\n",
      "<sentences>\n",
      "<sentence id=\"1\">\n",
      "<tokens>\n",
      "<token id=\"1\">\n",
      "<word>The</word>\n",
      "<lemma>the</lemma>\n",
      "<CharacterOffsetBegin>0</CharacterOffsetBegin>\n",
      "<CharacterOffsetEnd>3</CharacterOffsetEnd>\n",
      "<POS>DT</POS>\n",
      "<NER>O</NER>\n",
      "</token>\n",
      "<token id=\"2\">\n",
      "<word>basic</word>\n",
      "<lemma>basic</lemma>\n",
      "<CharacterOffsetBegin>4</CharacterOffsetBegin>\n",
      "<CharacterOffsetEnd>9</CharacterOffsetEnd>\n",
      "<POS>JJ</POS>\n",
      "<NER>O</NER>\n",
      "</token>\n",
      "<token id=\"3\">\n",
      "<word>plot</word>\n",
      "<lemma>plot</lemma>\n",
      "<CharacterOffsetBegin>10</CharacterOffsetBegin>\n",
      "<CharacterOffsetEnd>14</CharacterOffsetEnd>\n",
      "<POS>NN</POS>\n",
      "<NER>O</NER>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "file_path = '../data/RawDatasets/corenlp_plot_summaries/1031545.xml.gz'\n",
    "\n",
    "\n",
    "with gzip.open(file_path, 'rt', encoding='utf-8') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "for line in content[:30]:  # Adjust the number to see more or fewer lines. Now it's 0~30\n",
    "    print(line.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783097a3-7daf-46e4-a293-a0230889ca7a",
   "metadata": {},
   "source": [
    "# Part 2 : Show the sentence of each summary\n",
    "\n",
    "I have uploaded 61 files out of 27701(?) files.\n",
    "First 3 files' content is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ebe3d3b-3045-4d6c-b04e-8c4f7dd655b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T09:45:58.266552Z",
     "iopub.status.busy": "2024-11-08T09:45:58.266067Z",
     "iopub.status.idle": "2024-11-08T09:45:58.297074Z",
     "shell.execute_reply": "2024-11-08T09:45:58.294985Z",
     "shell.execute_reply.started": "2024-11-08T09:45:58.266518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1031545.xml.gz...\n",
      "Extracted sentence: The basic plot concept bears a strong similarity to the earlier movie Red Sun , also featuring Toshiro Mifune .\n",
      "Processing 1495388.xml.gz...\n",
      "Extracted sentence: \\* Winnie the Pooh and the Honey Tree \\* Winnie the Pooh and the Blustery Day \\* Winnie the Pooh and Tigger Too\n",
      "Processing 2372198.xml.gz...\n",
      "Extracted sentence: After the death of his outlaw brother , Jesse , Frank James seeks revenge on his killers , Bob and Charlie Ford .\n",
      "Total files processed: 3 out of 61\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "# Function to split a filename into numeric and non-numeric parts for natural sorting\n",
    "def natural_key(filename):\n",
    "    # Split the filename into a list of numeric and non-numeric parts\n",
    "    return [int(part) if part.isdigit() else part for part in re.split(r'(\\d+)', filename)]\n",
    "\n",
    "# Specify the directory containing your XML files\n",
    "directory = '../data/RawDatasets/corenlp_plot_summaries'\n",
    "\n",
    "# Get all the .xml.gz files in the directory and sort them using the natural key\n",
    "files = [f for f in os.listdir(directory) if f.endswith('.xml.gz')]\n",
    "sorted_files = sorted(files, key=natural_key)\n",
    "\n",
    "# Initialize counters\n",
    "total_files = len(sorted_files)\n",
    "processed_files = 0\n",
    "\n",
    "for filename in sorted_files[:3]:\n",
    "    print(f'Processing {filename}...')\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    \n",
    "    with gzip.open(file_path, 'rt', encoding='utf-8') as file:\n",
    "        # Parse the XML content\n",
    "        try:\n",
    "            tree = ET.parse(file)\n",
    "            root = tree.getroot()\n",
    "            sentences = root.find('.//sentences')\n",
    "            \n",
    "            if sentences is not None:\n",
    "                # Increment processed_files only once for the file\n",
    "                processed_files += 1  \n",
    "                \n",
    "                for sentence in sentences.findall('sentence'):\n",
    "                    tokens = sentence.find('tokens')\n",
    "                    if tokens is not None:\n",
    "                        # Extract the sentence text with proper spacing\n",
    "                        sentence_text = ' '.join(token.find('word').text for token in tokens.findall('token'))\n",
    "                        print(f'Extracted sentence: {sentence_text}')\n",
    "                    else:\n",
    "                        print('No tokens found in this sentence.')\n",
    "            else:\n",
    "                print('No sentences found in the file.')\n",
    "                \n",
    "        except ET.ParseError:\n",
    "            print(f'Error parsing {filename}')\n",
    "\n",
    "# Final output of processed file count\n",
    "print(f'Total files processed: {processed_files} out of {total_files}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2806e9b8-3c99-4c7b-8593-7e4087f3e3f5",
   "metadata": {},
   "source": [
    "# Part 3 : Relation to Movie Metadata\n",
    "\n",
    "Verified that the file name is the movie id in metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212cfddd-1f9a-4a0f-92f7-da31455db885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T09:45:58.303297Z",
     "iopub.status.busy": "2024-11-08T09:45:58.297973Z",
     "iopub.status.idle": "2024-11-08T09:45:58.362398Z",
     "shell.execute_reply": "2024-11-08T09:45:58.359626Z",
     "shell.execute_reply.started": "2024-11-08T09:45:58.303251Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_movie_metadata(filepath):\n",
    "    # Load the metadata with appropriate column names\n",
    "    column_names = ['movieId', 'uniqueId', 'title', 'releaseDate', 'duration', 'rating', 'languages', 'countries', 'genres']\n",
    "    metadata_df = pd.read_csv(filepath, sep='\\t', header=None, names=column_names)\n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd7a65a5-ad0d-4dc8-b659-6380fdf0b02c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T09:45:58.366117Z",
     "iopub.status.busy": "2024-11-08T09:45:58.365272Z",
     "iopub.status.idle": "2024-11-08T09:45:58.393758Z",
     "shell.execute_reply": "2024-11-08T09:45:58.391315Z",
     "shell.execute_reply.started": "2024-11-08T09:45:58.366042Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_movie_ids_in_filenames(metadata_df, xml_folder):\n",
    "    \"\"\"\n",
    "    Check if XML filenames correspond to movie IDs in the metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    - metadata_df (DataFrame): DataFrame containing movie metadata.\n",
    "    - xml_folder (str): Path to the folder containing XML files.\n",
    "    \n",
    "    Returns:\n",
    "    - matches (list): A list of filenames that match movie IDs.\n",
    "    \"\"\"\n",
    "    movie_ids = metadata_df['movieId'].astype(str).tolist()\n",
    "    matches = []\n",
    "\n",
    "    # Iterate over XML files in the specified directory\n",
    "    for filename in os.listdir(xml_folder):\n",
    "        if filename.endswith('.xml.gz'):  # Filter for XML files\n",
    "            movie_id = filename.split('.')[0]  # Extract the movie ID from the filename\n",
    "            if movie_id in movie_ids:\n",
    "                matches.append((movie_id, filename))\n",
    "\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cdbe1bb-75df-4bbe-b2a9-6936f1a71a43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T09:45:58.401518Z",
     "iopub.status.busy": "2024-11-08T09:45:58.396950Z",
     "iopub.status.idle": "2024-11-08T09:45:58.437512Z",
     "shell.execute_reply": "2024-11-08T09:45:58.436528Z",
     "shell.execute_reply.started": "2024-11-08T09:45:58.401404Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_movie_metadata(filepath):\n",
    "    # Load the metadata with appropriate column names\n",
    "    column_names = ['movieId', 'uniqueId', 'title', 'releaseDate', 'duration', 'rating', 'languages', 'countries', 'genres']\n",
    "    metadata_df = pd.read_csv(filepath, sep='\\t', header=None, names=column_names)\n",
    "    return metadata_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d12da9b6-a22d-4c3f-a9cb-5665cd1ed150",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T09:45:58.440214Z",
     "iopub.status.busy": "2024-11-08T09:45:58.439871Z",
     "iopub.status.idle": "2024-11-08T09:45:59.083894Z",
     "shell.execute_reply": "2024-11-08T09:45:59.082294Z",
     "shell.execute_reply.started": "2024-11-08T09:45:58.440180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found: Movie ID 2740181 corresponds to file 2740181.xml.gz\n",
      "Match found: Movie ID 1031545 corresponds to file 1031545.xml.gz\n",
      "Match found: Movie ID 9204672 corresponds to file 9204672.xml.gz\n",
      "Match found: Movie ID 19816863 corresponds to file 19816863.xml.gz\n",
      "Match found: Movie ID 17061845 corresponds to file 17061845.xml.gz\n",
      "Match found: Movie ID 10396322 corresponds to file 10396322.xml.gz\n",
      "Match found: Movie ID 17906343 corresponds to file 17906343.xml.gz\n",
      "Match found: Movie ID 8906897 corresponds to file 8906897.xml.gz\n",
      "Match found: Movie ID 14404921 corresponds to file 14404921.xml.gz\n",
      "Match found: Movie ID 5606938 corresponds to file 5606938.xml.gz\n"
     ]
    }
   ],
   "source": [
    "# Load movie metadata\n",
    "movie_meta_filepath = '../data/RawDatasets/MovieSummaries/movie.metadata.tsv'\n",
    "metadata_df = load_movie_metadata(movie_meta_filepath)\n",
    "\n",
    "# Specify the path to your XML files\n",
    "xml_folder_path = '../data/RawDatasets/corenlp_plot_summaries/'\n",
    "\n",
    "# Check for matches\n",
    "matching_files = check_movie_ids_in_filenames(metadata_df, xml_folder_path)\n",
    "\n",
    "# Print matches\n",
    "for movie_id, filename in matching_files[:10]:\n",
    "    print(f\"Match found: Movie ID {movie_id} corresponds to file {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e567a-3849-46cf-9358-cc02281cca15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
